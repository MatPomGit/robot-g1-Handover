# SÅ‚ownik TerminÃ³w (Glossary)

## ğŸ“– Wprowadzenie

Ten dokument wyjaÅ›nia kluczowe terminy i koncepty uÅ¼ywane w projekcie Robot G1 Handover. Idealny dla studentÃ³w rozpoczynajÄ…cych pracÄ™ z robotykÄ… i ROS 2.

---

## ğŸ¤– Podstawowe Koncepty Robotyki

### Robot Humanoidalny
Robot zbudowany tak, aby przypominaÅ‚ czÅ‚owieka - ma tuÅ‚Ã³w, ramiona, nogi, czasem gÅ‚owÄ™. Unitree G1 to przykÅ‚ad humanoidalnego robota.

**Dlaczego humanoidalny?** Åatwiej wchodzi w interakcje z ludÅºmi i moÅ¼e uÅ¼ywaÄ‡ narzÄ™dzi zaprojektowanych dla ludzi.

### End-Effector (Efektor KoÅ„cowy)
Ostatni element ramienia robota - to co bezpoÅ›rednio wykonuje zadanie. W naszym przypadku: **gripper** (chwytak).

**PrzykÅ‚ady end-effectorÃ³w**:
- Gripper (chwytak) - chwyta obiekty
- Suction cup (przyssawka) - podnosi pÅ‚askie przedmioty
- Tool (narzÄ™dzie) - wkrÄ™tarka, lutownica, itp.

### Degrees of Freedom (DOF, Stopnie Swobody)
Liczba niezaleÅ¼nych ruchÃ³w, ktÃ³re robot moÅ¼e wykonaÄ‡. Robot G1 ma:
- RamiÄ™: 7 DOF (bardziej niÅ¼ ludzkie ramiÄ™!)
- Gripper: 1-2 DOF (otwÃ³rz/zamknij)

**Im wiÄ™cej DOF, tym robot bardziej zrÄ™czny, ale trudniejszy w sterowaniu.**

### Workspace (PrzestrzeÅ„ Robocza)
Obszar, do ktÃ³rego robot moÅ¼e dosiÄ™gnÄ…Ä‡ swoim ramieniem. Dla G1: okoÅ‚o 0.3-0.8m od bazy.

**Poza workspace**: Robot nie moÅ¼e wykonaÄ‡ ruchu (IK nie ma rozwiÄ…zania).

### Trajectory (Trajektoria)
ÅšcieÅ¼ka, ktÃ³rÄ… ramiÄ™ robota przebywa z punktu A do punktu B. Zawiera:
- Pozycje poÅ›rednie (waypoints)
- PrÄ™dkoÅ›ci
- Przyspieszenia

**Dobra trajektoria**: PÅ‚ynna, unika kolizji, bezpieczna dla czÅ‚owieka.

---

## ğŸ”§ ROS 2 (Robot Operating System 2)

### Node (WÄ™zeÅ‚)
Pojedynczy proces wykonujÄ…cy okreÅ›lone zadanie. PrzykÅ‚ady z naszego projektu:
- `object_detector` - wykrywa obiekty
- `execute_grasp` - wykonuje chwytanie

**Filozofia ROS**: Wiele maÅ‚ych node'Ã³w wspÃ³Å‚pracujÄ…cych ze sobÄ…, zamiast jednego duÅ¼ego programu.

### Topic (Temat)
KanaÅ‚ komunikacji miÄ™dzy node'ami. Node'y mogÄ…:
- **PublikowaÄ‡** (publish) - wysyÅ‚aÄ‡ dane
- **SubskrybowaÄ‡** (subscribe) - odbieraÄ‡ dane

**PrzykÅ‚ad**:
```
object_detector (publisher) ---> /object_detections ---> execute_grasp (subscriber)
```

### Message (WiadomoÅ›Ä‡)
Struktura danych przesyÅ‚ana przez topic. Typy wiadomoÅ›ci:
- `std_msgs/Bool` - prawda/faÅ‚sz
- `geometry_msgs/PoseStamped` - pozycja 3D + orientacja
- `sensor_msgs/Image` - obraz z kamery

**Podobnie jak**: Klasa w Pythonie lub struct w C.

### Service (UsÅ‚uga)
Komunikacja typu request-response (zapytanie-odpowiedÅº). W przeciwieÅ„stwie do topikÃ³w:
- Synchroniczna (czeka na odpowiedÅº)
- Jednorazowa (nie ciÄ…gÅ‚y strumieÅ„)

**PrzykÅ‚ad**: `emergency_stop` - wywoÅ‚aj aby zatrzymaÄ‡ robota.

### TF (Transform Framework)
System zarzÄ…dzania ukÅ‚adami wspÃ³Å‚rzÄ™dnych. Pozwala konwertowaÄ‡ pozycje miÄ™dzy ramkami:
- `base_link` â†’ `camera_link` - gdzie jest kamera wzglÄ™dem bazy robota?
- `camera_link` â†’ `object` - gdzie jest obiekt wzglÄ™dem kamery?

**Kluczowe dla**: Percepcji 3D i planowania ruchu.

### Launch File
Plik Python uruchamiajÄ…cy wiele node'Ã³w jednoczeÅ›nie z odpowiedniÄ… konfiguracjÄ….

**Zamiast**:
```bash
ros2 run pkg node1 &
ros2 run pkg node2 &
ros2 run pkg node3 &
```

**UÅ¼ywamy**:
```bash
ros2 launch pkg my_system.launch.py
```

---

## ğŸ“¸ Computer Vision (Widzenie Komputerowe)

### RGB-D Camera (Kamera RGB-D)
Kamera, ktÃ³ra rejestruje:
- **RGB**: Obraz kolorowy (Red, Green, Blue)
- **D**: Depth (gÅ‚Ä™bokoÅ›Ä‡) - odlegÅ‚oÅ›Ä‡ kaÅ¼dego piksela od kamery

**PrzykÅ‚ady**: Intel RealSense D435, Azure Kinect, Kinect v2

### Object Detection (Detekcja ObiektÃ³w)
Znalezienie obiektÃ³w na obrazie i narysowanie ramek (bounding boxes) wokÃ³Å‚ nich.

**Output**: Lista obiektÃ³w z:
- KlasÄ… (np. "cup", "phone")
- Confidence (pewnoÅ›Ä‡, 0-1)
- Bounding box (x, y, width, height)

### YOLO (You Only Look Once)
Szybki algorytm detekcji obiektÃ³w. "Only Once" = jeden przebieg przez sieÄ‡ neuronowÄ….

**Wersje**:
- YOLOv3, v4, v5, v7, v8, v10
- YOLOv5s (small, szybki) â†’ YOLOv5x (extra large, dokÅ‚adny)

### Bounding Box
ProstokÄ…t opisujÄ…cy pozycjÄ™ obiektu na obrazie.

**Format**:
- (x, y, width, height) - lewy gÃ³rny rÃ³g + wymiary
- (x_min, y_min, x_max, y_max) - dwa przeciwlegÅ‚e rogi

### 6D Pose (Poza 6D)
PeÅ‚ny opis pozycji i orientacji obiektu w przestrzeni 3D:
- **3D Position**: (x, y, z) - gdzie jest obiekt
- **3D Orientation**: (roll, pitch, yaw) lub quaternion - jak jest obrÃ³cony

**6 = 3 (position) + 3 (orientation)**

### Pinhole Camera Model
Matematyczny model kamery opisujÄ…cy jak punkty 3D sÄ… projektowane na obraz 2D.

**Parametry**:
- `fx, fy` - dÅ‚ugoÅ›Ä‡ ogniskowa (focal length)
- `cx, cy` - optyczny Å›rodek (principal point)

**FormuÅ‚a**: 
```
u = fx * (X / Z) + cx
v = fy * (Y / Z) + cy
```

### Depth Map (Mapa GÅ‚Ä™bokoÅ›ci)
Obraz, gdzie kaÅ¼dy piksel reprezentuje odlegÅ‚oÅ›Ä‡ od kamery (zamiast koloru).

**Reprezentacja**:
- Jasny piksel = daleko
- Ciemny piksel = blisko
- Czarny = brak danych (invalid depth)

---

## ğŸ¦¾ Motion Planning (Planowanie Ruchu)

### MoveIt 2
Framework do planowania ruchu manipulatorÃ³w w ROS 2. Zawiera:
- Plannery (algorytmy)
- Collision checking
- Inverse kinematics (IK)
- Trajectory execution

### Inverse Kinematics (IK, Kinematyka Odwrotna)
Obliczanie kÄ…tÃ³w stawÃ³w dla zadanej pozycji end-effectora.

**Problem**:
- Dana: Pozycja (x, y, z) gdzie chcemy aby byÅ‚ gripper
- Szukana: KÄ…ty stawÃ³w (Î¸1, Î¸2, ..., Î¸7) aby to osiÄ…gnÄ…Ä‡

**TrudnoÅ›Ä‡**: MoÅ¼e byÄ‡ wiele rozwiÄ…zaÅ„ lub brak rozwiÄ…zania!

### Forward Kinematics (FK, Kinematyka Wprost)
OdwrotnoÅ›Ä‡ IK: obliczanie pozycji end-effectora z kÄ…tÃ³w stawÃ³w.

**Problem**:
- Dane: KÄ…ty stawÃ³w (Î¸1, Î¸2, ..., Î¸7)
- Szukana: Pozycja (x, y, z) grippera

**Åatwiejsze niÅ¼ IK** - zawsze jedno rozwiÄ…zanie.

### Planning Scene
Reprezentacja otoczenia robota w MoveIt. Zawiera:
- Przeszkody (stÃ³Å‚, Å›ciany, czÅ‚owiek)
- Robot i jego model
- Attached objects (obiekt w chwytaku)

**UÅ¼ywane do**: Collision detection podczas planowania.

### Collision Detection
Sprawdzanie czy trajektoria robota uderzy w przeszkodÄ™.

**MoveIt robi to automatycznie!** Planner odrzuca trajektorie z kolizjami.

### RRT (Rapidly-exploring Random Tree)
Popularny algorytm planowania trajektorii. DziaÅ‚a poprzez:
1. Losowe prÃ³bkowanie przestrzeni konfiguracji
2. Budowanie drzewa od startu do celu
3. Znajdowanie Å›cieÅ¼ki w drzewie

**Warianty**:
- RRTConnect - dwukierunkowy (szybki)
- RRTstar - optymalizuje trajektoriÄ™ (wolny, lepszy)

### Trajectory Smoothing
WygÅ‚adzanie trajektorii aby ruch byÅ‚ pÅ‚ynniejszy.

**Przed**: ZaÅ‚amane, ostre zakrÄ™ty
**Po**: PÅ‚ynne przejÅ›cia, naturalne ruchy

### Velocity Scaling
Skalowanie prÄ™dkoÅ›ci ruchu.

**Zastosowanie**:
- `0.1` - bardzo wolno (testowanie, bezpieczeÅ„stwo)
- `0.5` - Å›rednio (normalna praca)
- `1.0` - maksymalna prÄ™dkoÅ›Ä‡ (tylko dla eksperta!)

---

## ğŸ§  Artificial Intelligence (Sztuczna Inteligencja)

### World Model
Model AI przewidujÄ…cy jak zmieni siÄ™ Å›rodowisko po wykonaniu akcji.

**Koncept**:
```
Stan obecny + Akcja â†’ World Model â†’ Stan przyszÅ‚y (przewidywany)
```

**UÅ¼ycie**: Planowanie wieloetapowe (co siÄ™ stanie jeÅ›li...).

### WMA (World Model AI)
Konkretna implementacja World Model uÅ¼ywana w tym projekcie.

**Komponenty**:
- Encoder - przetwarza obserwacje
- World Model - przewiduje przyszÅ‚oÅ›Ä‡
- Policy - wybiera akcje

### Policy (Polityka)
Funkcja wybierajÄ…ca akcjÄ™ na podstawie obserwacji.

**Typy**:
- Deterministyczna - zawsze ta sama akcja dla danej obserwacji
- Stochastyczna - losuje akcjÄ™ z rozkÅ‚adu prawdopodobieÅ„stwa

### Observation (Obserwacja)
Dane wejÅ›ciowe dla AI - wszystko co "widzi" system:
- Obraz z kamery
- Pozycja dÅ‚oni czÅ‚owieka
- Stan chwytaka
- Czujniki siÅ‚y

### Action (Akcja)
Decyzja AI - co robot ma zrobiÄ‡:
- `TAKE_FROM_HUMAN` - odbierz obiekt
- `GIVE_TO_HUMAN` - przekaÅ¼ obiekt
- `IDLE` - czekaj

### Inference (Wnioskowanie)
Uruchomienie wytrenowanego modelu AI na nowych danych.

**Proces**:
```
Obserwacje â†’ Preprocessing â†’ Model AI â†’ Akcja
```

### Checkpoint
Zapisany stan wytrenowanego modelu AI (wagi sieci neuronowej).

**Plik**: `.pth` (PyTorch), `.h5` (Keras), `.onnx` (uniwersalny)

---

## ğŸ¤ Human-Robot Interaction (HRI)

### Handover
Przekazywanie obiektÃ³w miÄ™dzy czÅ‚owiekiem a robotem.

**Typy**:
- Human-to-Robot (H2R): CzÅ‚owiek daje obiekt robotowi
- Robot-to-Human (R2H): Robot daje obiekt czÅ‚owiekowi

### Intention Recognition (Rozpoznawanie Intencji)
OkreÅ›lanie czego chce czÅ‚owiek na podstawie gestÃ³w, pozy ciaÅ‚a, wzroku.

**W naszym projekcie**: `human_reaching` - czy czÅ‚owiek wyciÄ…ga rÄ™kÄ™?

### Ergonomics (Ergonomia)
Projektowanie interakcji tak, aby byÅ‚y wygodne i naturalne dla czÅ‚owieka.

**PrzykÅ‚ad**: Robot przekazuje obiekt nieco poniÅ¼ej dÅ‚oni czÅ‚owieka (offset -5cm), aby byÅ‚o Å‚atwiej go chwyciÄ‡.

### Safety Zone (Strefa BezpieczeÅ„stwa)
Obszar wokÃ³Å‚ czÅ‚owieka, do ktÃ³rego robot nie moÅ¼e wjechaÄ‡ zbyt szybko.

**W kodzie**: `EMERGENCY_STOP_DISTANCE = 0.05m`

---

## ğŸ”„ State Machine (Automat StanÃ³w)

### FSM (Finite State Machine)
System z ograniczonÄ… liczbÄ… stanÃ³w i przejÅ›Ä‡ miÄ™dzy nimi.

**W naszym projekcie**:
```
idle â†’ approach â†’ grasp â†’ lift
```

### State (Stan)
Sytuacja, w ktÃ³rej znajduje siÄ™ system.

**PrzykÅ‚ady**:
- `idle` - czekanie
- `approach` - podchodzenie
- `grasp` - chwytanie

### Transition (PrzejÅ›cie)
Zmiana ze stanu A do stanu B.

**Warunek przejÅ›cia**: "Co musi siÄ™ staÄ‡, aby zmieniÄ‡ stan?"

**PrzykÅ‚ad**: `idle â†’ approach` jeÅ›li wykryto obiekt.

---

## ğŸ“¦ Manipulation (Manipulacja)

### Grasp (Chwyt)
Uchwycenie obiektu chwytakiem.

**Typy chwytÃ³w**:
- Top grasp - z gÃ³ry (najczÄ™stszy w naszym projekcie)
- Side grasp - z boku
- Power grasp - mocny chwyt (caÅ‚Ä… dÅ‚oniÄ…)
- Precision grasp - precyzyjny (palcami)

### Pre-grasp
Pozycja tuÅ¼ przed chwyceniem - zwykle nad obiektem.

**Dlaczego?** Bezpieczne podejÅ›cie, unikniÄ™cie kolizji ze stoÅ‚em.

### Gripper (Chwytak)
Mechanizm na koÅ„cu ramienia sÅ‚uÅ¼Ä…cy do chwytania.

**Typy**:
- Parallel jaw - dwie rÃ³wnolegÅ‚e szczÄ™ki
- Suction - przyssawka
- Soft gripper - miÄ™kki, dopasowuje siÄ™ do ksztaÅ‚tu

### Force Control (Sterowanie SiÅ‚owe)
Kontrola siÅ‚y, z jakÄ… chwytak Å›ciska obiekt.

**WaÅ¼ne**: Nie zmiaÅ¼dÅ¼yÄ‡ delikatnych obiektÃ³w (jajko, telefon).

---

## ğŸ›¡ï¸ Safety (BezpieczeÅ„stwo)

### E-STOP (Emergency Stop)
Natychmiastowe zatrzymanie wszystkich ruchÃ³w robota.

**Typy**:
- Hardware - fizyczny przycisk
- Software - komenda ROS 2

### Collision Avoidance
Unikanie kolizji z przeszkodami.

**Metody**:
- Planning-time - sprawdzanie podczas planowania
- Runtime - monitorowanie podczas ruchu

### Velocity Limiting
Ograniczenie maksymalnej prÄ™dkoÅ›ci ruchu.

**BezpieczeÅ„stwo**: Wolniejszy robot = bezpieczniejszy dla czÅ‚owieka.

---

## ğŸ“Š Metrics (Metryki)

### Success Rate
Odsetek udanych prÃ³b wykonania zadania.

**PrzykÅ‚ad**: Robot udanie chwyciÅ‚ obiekt w 9 na 10 prÃ³b = 90% success rate.

### Latency (OpÃ³Åºnienie)
Czas od wykrycia obiektu do rozpoczÄ™cia ruchu.

**Cel**: Jak najniÅ¼sze (real-time response).

### Accuracy (DokÅ‚adnoÅ›Ä‡)
Jak blisko robot trafi do celu.

**PrzykÅ‚ad**: Robot powinien trafiÄ‡ w punkt (0.5, 0.0, 0.5), trafiÅ‚ w (0.51, 0.01, 0.49) â†’ bÅ‚Ä…d ~1.4cm.

### FPS (Frames Per Second)
Ile klatek na sekundÄ™ przetwarza system percepcji.

**Typowe wartoÅ›ci**:
- 10 FPS - minimalne dla robotyki
- 30 FPS - dobre
- 60+ FPS - Å›wietne

---

## ğŸ“ Dla StudentÃ³w

### Debugging
Proces znajdowania i naprawiania bÅ‚Ä™dÃ³w w kodzie.

**NarzÄ™dzia**:
- `print()` / `self.get_logger().info()` - wypisywanie wartoÅ›ci
- RViz - wizualizacja
- `ros2 topic echo` - podglÄ…danie danych
- Debugger (pdb, gdb) - krok po kroku

### Visualization (Wizualizacja)
Graficzne przedstawienie danych.

**NarzÄ™dzia**:
- RViz2 - gÅ‚Ã³wne narzÄ™dzie ROS 2
- Matplotlib - wykresy
- OpenCV - obrazy

### Simulation (Symulacja)
Testowanie robota w Å›rodowisku wirtualnym przed uÅ¼yciem prawdziwego.

**Zalety**:
- Bezpieczne (Å¼adne szkody)
- Szybsze iteracje
- MoÅ¼na testowaÄ‡ niebezpieczne scenariusze

**NarzÄ™dzia**: Gazebo, MuJoCo, Isaac Sim

---

## ğŸ“š Dodatkowe Terminy

### URDF (Unified Robot Description Format)
XML opisujÄ…cy geometriÄ™ i kinematykÄ™ robota.

### SRDF (Semantic Robot Description Format)
Dodatkowe informacje semantyczne dla MoveIt (grupy, stany).

### Bag File
Plik z nagranym zapisem danych ROS 2. MoÅ¼na odtworzyÄ‡.

### Remapping
Zmiana nazwy topiku:
```bash
ros2 run pkg node --ros-args -r old_topic:=new_topic
```

### Parameter
Konfigurowalna wartoÅ›Ä‡ w node (moÅ¼na zmieniÄ‡ bez rebuildu).

---

**Masz pytanie o inny termin?** OtwÃ³rz Issue i dodamy go do sÅ‚ownika!
