# FAQ i RozwiÄ…zywanie ProblemÃ³w (Troubleshooting)

## ğŸ“– Wprowadzenie

Ten dokument zawiera odpowiedzi na najczÄ™Å›ciej zadawane pytania oraz rozwiÄ…zania typowych problemÃ³w spotykanych podczas pracy z systemem Robot G1 Handover.

## ğŸ”§ Instalacja i Konfiguracja

### Q: Jak sprawdziÄ‡, czy ROS 2 jest poprawnie zainstalowany?

```bash
# SprawdÅº wersjÄ™ ROS 2
ros2 --version

# SprawdÅº czy moÅ¼na uruchomiÄ‡ przykÅ‚adowy node
ros2 run demo_nodes_cpp talker

# W drugim terminalu
ros2 run demo_nodes_cpp listener
```

**Oczekiwany rezultat**: Listener odbiera wiadomoÅ›ci od Talker.

### Q: Pakiet nie buduje siÄ™ - bÅ‚Ä…d "package not found"

**Problem**: `colcon build` zwraca bÅ‚Ä…d o brakujÄ…cych zaleÅ¼noÅ›ciach.

**RozwiÄ…zanie**:
```bash
# Zainstaluj zaleÅ¼noÅ›ci ROS 2
cd ~/ros2_ws
rosdep install --from-paths src --ignore-src -r -y

# SprawdÅº czy wszystkie zaleÅ¼noÅ›ci sÄ… zainstalowane
rosdep check g1_pick_and_handover
```

### Q: Jak zaktualizowaÄ‡ zaleÅ¼noÅ›ci Python?

```bash
# Zaktualizuj pip
pip3 install --upgrade pip

# Zainstaluj wymagane pakiety
pip3 install -r requirements.txt

# SprawdÅº zainstalowane wersje
pip3 list | grep torch
pip3 list | grep opencv
```

## ğŸ¥ Kamera i Percepcja

### Q: Kamera nie jest wykrywana przez system

**Problem**: ROS 2 nie widzi topikÃ³w z kamery (`/camera/color/image_raw`).

**RozwiÄ…zanie**:
```bash
# SprawdÅº czy kamera jest podÅ‚Ä…czona (dla RealSense)
rs-enumerate-devices

# Uruchom driver kamery RealSense
ros2 run realsense2_camera realsense2_camera_node

# SprawdÅº dostÄ™pne topiki
ros2 topic list | grep camera
```

**Alternatywa**: UÅ¼yj danych testowych:
```bash
# OdtwÃ³rz bag z nagranym zapisem
ros2 bag play test_data.bag
```

### Q: YOLOv5 nie wykrywa obiektÃ³w

**Problem**: `/object_detections` jest pusty mimo obiektÃ³w w kadrze.

**Sprawdzenia**:
1. Czy obiekt jest w zbiorze COCO (80 klas)?
2. Czy prÃ³g pewnoÅ›ci nie jest zbyt wysoki?
3. Czy oÅ›wietlenie jest odpowiednie?

**RozwiÄ…zanie**:
```bash
# ObniÅ¼ prÃ³g pewnoÅ›ci
ros2 run g1_pick_and_handover object_detector \
    --ros-args -p confidence_threshold:=0.3

# UÅ¼yj wiÄ™kszego modelu (dokÅ‚adniejszy)
ros2 run g1_pick_and_handover object_detector \
    --ros-args -p model_name:=yolov5m
```

**Testowanie offline**:
```python
import torch
model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
results = model('test_image.jpg')
results.show()  # Zobacz czy wykrywa obiekty
```

### Q: NieprawidÅ‚owa pozycja 3D obiektu

**Problem**: `/object_pose` zwraca bÅ‚Ä™dne wspÃ³Å‚rzÄ™dne (x, y, z).

**Sprawdzenia**:
1. Czy kamera jest skalibrowana?
2. Czy transformacja TF jest poprawna?
3. Czy mapa gÅ‚Ä™bokoÅ›ci jest poprawna?

**RozwiÄ…zanie**:
```bash
# SprawdÅº transformacjÄ™ kamery
ros2 run tf2_ros tf2_echo base_link camera_link

# SprawdÅº parametry kalibracji
ros2 topic echo /camera/color/camera_info --once

# Wizualizuj w RViz
rviz2
# Dodaj: TF, Image, PoseStamped
```

**Kalibracja kamery** (jeÅ›li potrzebna):
```bash
ros2 run camera_calibration cameracalibrator \
    --size 8x6 --square 0.025 \
    image:=/camera/color/image_raw
```

### Q: MediaPipe nie wykrywa dÅ‚oni

**Problem**: `/human_hand_pose` nie publikuje pozycji dÅ‚oni.

**RozwiÄ…zania**:
1. Upewnij siÄ™, Å¼e dÅ‚oÅ„ jest dobrze oÅ›wietlona
2. DÅ‚oÅ„ powinna byÄ‡ wyraÅºnie widoczna (bez zasÅ‚oniÄ™Ä‡)
3. SprawdÅº czy MediaPipe jest zainstalowany:
   ```bash
   pip3 show mediapipe
   ```

**Test MediaPipe**:
```python
import mediapipe as mp
import cv2

mp_hands = mp.solutions.hands
hands = mp_hands.Hands()

cap = cv2.VideoCapture(0)
ret, frame = cap.read()
results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

if results.multi_hand_landmarks:
    print("DÅ‚oÅ„ wykryta!")
else:
    print("Brak detekcji dÅ‚oni")
```

## ğŸ¦¾ MoveIt 2 i Manipulacja

### Q: MoveIt 2 nie planuje trajektorii

**Problem**: `Planning failed` w logach.

**MoÅ¼liwe przyczyny i rozwiÄ…zania**:

1. **Pozycja poza workspace robota**
   ```python
   # SprawdÅº czy pozycja jest w zasiÄ™gu
   distance = sqrt(x**2 + y**2 + z**2)
   print(f"Distance to target: {distance}m")
   # Dla G1: workspace zwykle 0.3-0.8m
   ```

2. **Kolizja z przeszkodami**
   ```bash
   # Wizualizuj scenÄ™ planowania w RViz
   # Dodaj display: PlanningScene
   # SprawdÅº czy przeszkody sÄ… poprawnie zdefiniowane
   ```

3. **IK nie ma rozwiÄ…zania**
   ```python
   # ZwiÄ™ksz tolerancjÄ™
   self.arm.set_goal_position_tolerance(0.01)
   self.arm.set_goal_orientation_tolerance(0.05)
   ```

4. **Timeout planowania**
   ```python
   # ZwiÄ™ksz czas planowania
   self.arm.set_planning_time(15.0)
   ```

### Q: Robot wykonuje dziwne ruchy

**Problem**: Trajektoria jest nienaturalna lub robot uderza w przeszkody.

**RozwiÄ…zania**:
```python
# ZmieÅ„ planner
self.arm.set_planner_id("RRTstar")  # Zamiast RRTConnect

# Zmniejsz prÄ™dkoÅ›Ä‡
self.arm.set_max_velocity_scaling_factor(0.3)

# Dodaj wiÄ™cej przeszkÃ³d do sceny
from manipulation.planning_scene import add_table, add_human
add_table(self.scene)
add_human(self.scene)
```

### Q: Gripper nie chwyta obiektu

**Problem**: Chwytak zamyka siÄ™, ale obiekt wypada.

**Sprawdzenia**:
1. Czy robot jest dokÅ‚adnie nad obiektem?
2. Czy chwytak jest wystarczajÄ…co duÅ¼y?
3. Czy obiekt nie jest zbyt Å›liski?

**RozwiÄ…zania**:
```yaml
# W config/grasp_params.yaml
grasp:
  approach_distance: 0.08  # Zmniejsz (bliÅ¼ej obiektu)
  gripper_closed: 0.005    # ZwiÄ™ksz siÅ‚Ä™ zamkniÄ™cia
  max_force: 40.0          # ZwiÄ™ksz maksymalnÄ… siÅ‚Ä™
```

**Dodanie czujnika siÅ‚y** (zaawansowane):
```python
def check_grasp_success(self):
    """SprawdÅº czy obiekt zostaÅ‚ chwycony"""
    force = self.get_gripper_force()
    if force < MIN_FORCE:
        self.get_logger().warn("Grasp may have failed")
        return False
    return True
```

## ğŸ§  WMA i Podejmowanie Decyzji

### Q: WMA nie jest dostÄ™pny

**Problem**: BÅ‚Ä…d `WMA not available, using mock decision making`.

**To jest normalne!** WMA jest zaawansowanym modelem AI, ktÃ³ry wymaga:
- Pretrenowanego checkpointu
- GPU (opcjonalnie, ale zalecane)
- Biblioteki `unifolm_wma` (nie jest publicznie dostÄ™pna)

**RozwiÄ…zanie - tryb mock**:
System automatycznie uÅ¼ywa prostych reguÅ‚ if-else:
```python
if human_reaching and not gripper_occupied:
    action = "TAKE_FROM_HUMAN"
elif human_reaching and gripper_occupied:
    action = "GIVE_TO_HUMAN"
else:
    action = "IDLE"
```

**To wystarczy do nauki i testowania systemu!**

### Q: Jak wytrenowaÄ‡ wÅ‚asny model WMA?

**Uwaga**: To zaawansowane zadanie wymagajÄ…ce znajomoÅ›ci ML.

**Krok po kroku**:
1. Zbierz dataset (100+ epizodÃ³w handover)
2. Format danych:
   ```
   dataset/
   â”œâ”€â”€ episode_0001/
   â”‚   â”œâ”€â”€ observations/
   â”‚   â”‚   â”œâ”€â”€ rgb_000.png
   â”‚   â”‚   â”œâ”€â”€ depth_000.png
   â”‚   â”‚   â””â”€â”€ state_000.json
   â”‚   â””â”€â”€ actions/
   â”‚       â””â”€â”€ action_000.txt
   ```
3. Wytrenuj model (wymaga PyTorch + GPU):
   ```bash
   python train_wma.py --dataset ./dataset --epochs 100
   ```

**Alternatywa**: UÅ¼yj Reinforcement Learning:
- Biblioteka: Stable Baselines 3
- Åšrodowisko: Gymnasium
- Algorytm: SAC lub PPO

## ğŸš€ Launch Files i Node'y

### Q: Launch file nie uruchamia wszystkich node'Ã³w

**Problem**: Tylko czÄ™Å›Ä‡ node'Ã³w siÄ™ uruchamia.

**Debugowanie**:
```bash
# Uruchom z logami na ekranie
ros2 launch g1_pick_and_handover full_handover_pipeline.launch.py --screen

# SprawdÅº aktywne node'y
ros2 node list

# SprawdÅº czy node siÄ™ crashuje
ros2 node info /node_name
```

**Typowe bÅ‚Ä™dy**:
- Brak zaleÅ¼noÅ›ci Python
- NieprawidÅ‚owa Å›cieÅ¼ka do pliku konfiguracyjnego
- Konflikt nazw node'Ã³w

### Q: Jak uruchomiÄ‡ pojedynczy node do testowania?

```bash
# Node z domyÅ›lnymi parametrami
ros2 run g1_pick_and_handover object_detector

# Node z custom parametrami
ros2 run g1_pick_and_handover object_detector \
    --ros-args \
    -p confidence_threshold:=0.7 \
    -p model_name:=yolov5m

# Node z plikiem konfiguracyjnym
ros2 run g1_pick_and_handover execute_grasp \
    --ros-args --params-file config/grasp_params.yaml
```

## ğŸ” Debugowanie

### Q: Jak sprawdziÄ‡ co siÄ™ dzieje w systemie?

**NarzÄ™dzia diagnostyczne**:

1. **Lista topikÃ³w**:
   ```bash
   ros2 topic list
   ```

2. **Monitorowanie topiku**:
   ```bash
   ros2 topic echo /object_pose
   ```

3. **CzÄ™stotliwoÅ›Ä‡ publikacji**:
   ```bash
   ros2 topic hz /camera/color/image_raw
   ```

4. **Wykres node'Ã³w**:
   ```bash
   rqt_graph
   ```

5. **Logi node'a**:
   ```bash
   ros2 node info /object_detector
   ```

### Q: Jak wÅ‚Ä…czyÄ‡ verbose logging?

```bash
# Dla pojedynczego node'a
ros2 run g1_pick_and_handover object_detector \
    --ros-args --log-level debug

# Dla launch file
ros2 launch g1_pick_and_handover full_handover_pipeline.launch.py \
    log_level:=debug
```

**W kodzie Python**:
```python
# Dodaj wiÄ™cej logÃ³w
self.get_logger().debug("Detailed debug info")
self.get_logger().info("General information")
self.get_logger().warn("Warning message")
self.get_logger().error("Error occurred")
```

### Q: Jak nagraÄ‡ i odtworzyÄ‡ dane?

**Nagrywanie (bag file)**:
```bash
# Nagraj wszystkie topiki
ros2 bag record -a

# Nagraj wybrane topiki
ros2 bag record /camera/color/image_raw /object_pose

# Nagraj z nazwÄ…
ros2 bag record -o my_test /camera/color/image_raw
```

**Odtwarzanie**:
```bash
# OdtwÃ³rz bag
ros2 bag play my_test.bag

# OdtwÃ³rz w pÄ™tli
ros2 bag play my_test.bag --loop

# OdtwÃ³rz wolniej (50% prÄ™dkoÅ›ci)
ros2 bag play my_test.bag --rate 0.5
```

## âš ï¸ BezpieczeÅ„stwo

### Q: Jak zatrzymaÄ‡ robota w nagÅ‚ych wypadkach?

**Emergency Stop**:
1. **Hardware E-STOP**: Czerwony przycisk (jeÅ›li dostÄ™pny)
2. **Software E-STOP**: 
   ```bash
   ros2 service call /emergency_stop std_srvs/srv/Trigger
   ```
3. **Keyboard**: `Ctrl+C` w terminalu z node'm
4. **Kill process**: 
   ```bash
   ps aux | grep ros2
   kill -9 <PID>
   ```

### Q: Jak ustawiÄ‡ bezpieczne prÄ™dkoÅ›ci?

**W kodzie**:
```python
# Bezpieczne wartoÅ›ci dla testÃ³w
self.arm.set_max_velocity_scaling_factor(0.3)  # 30% max prÄ™dkoÅ›ci
self.arm.set_max_acceleration_scaling_factor(0.3)  # 30% max przyspieszenia
```

**W konfiguracji**:
```yaml
# config/moveit.yaml
move_group:
  ros__parameters:
    default_velocity_scaling_factor: 0.3
    default_acceleration_scaling_factor: 0.3
```

### Q: Jak dodaÄ‡ strefy bezpieczeÅ„stwa?

```python
from manipulation.planning_scene import add_safety_zone

def add_safety_zone(scene, position, radius):
    """Dodaje sferÄ™ bezpieczeÅ„stwa"""
    pose = PoseStamped()
    pose.header.frame_id = "base_link"
    pose.pose.position.x = position[0]
    pose.pose.position.y = position[1]
    pose.pose.position.z = position[2]
    pose.pose.orientation.w = 1.0
    
    scene.add_sphere("safety_zone", pose, radius=radius)

# UÅ¼ycie
add_safety_zone(scene, position=[0.5, 0.0, 0.5], radius=0.2)
```

## ğŸ“ Dla StudentÃ³w

### Q: Od czego zaczÄ…Ä‡ naukÄ™ tego projektu?

**ÅšcieÅ¼ka nauki (krok po kroku)**:

1. **TydzieÅ„ 1**: Podstawy ROS 2
   - Zrozum koncepty: node, topic, message
   - Uruchom przykÅ‚adowy talker/listener
   - Naucz siÄ™ uÅ¼ywaÄ‡ `ros2 topic`, `ros2 node`

2. **TydzieÅ„ 2**: Percepcja
   - Uruchom `object_detector`
   - Zrozum jak dziaÅ‚a YOLOv5
   - Testuj detekcjÄ™ rÃ³Å¼nych obiektÃ³w

3. **TydzieÅ„ 3**: MoveIt 2
   - Zainstaluj MoveIt 2
   - Zaplanuj prostÄ… trajektoriÄ™ w RViz
   - Zrozum kinematykÄ™ odwrotnÄ… (IK)

4. **TydzieÅ„ 4**: Integracja
   - Uruchom caÅ‚y pipeline
   - Zaobserwuj przepÅ‚yw danych
   - Przetestuj na prawdziwym robocie (jeÅ›li dostÄ™pny)

### Q: Jakie projekty moÅ¼na zrobiÄ‡ na bazie tego repozytorium?

**PomysÅ‚y na projekty**:

1. **Åatwe** (1-2 tygodnie):
   - Dodaj detekcjÄ™ nowych klas obiektÃ³w (custom YOLOv5)
   - Zaimplementuj lepszÄ… estymacjÄ™ pozy (PnP, ICP)
   - StwÃ³rz GUI do monitorowania systemu (rqt plugin)

2. **Åšrednie** (3-4 tygodnie):
   - Dodaj multi-object grasp planning
   - Zaimplementuj force control dla chwytaka
   - Dodaj human skeleton tracking (caÅ‚e ciaÅ‚o, nie tylko dÅ‚oÅ„)

3. **Trudne** (1-2 miesiÄ…ce):
   - Wytrenuj wÅ‚asny model WMA
   - Zaimplementuj adaptive grasping (rÃ³Å¼ne strategie dla rÃ³Å¼nych obiektÃ³w)
   - Dodaj collision avoidance w czasie rzeczywistym

### Q: Gdzie znaleÅºÄ‡ wiÄ™cej informacji?

**Zasoby edukacyjne**:

- **ROS 2**: https://docs.ros.org/en/humble/Tutorials.html
- **MoveIt 2**: https://moveit.picknik.ai/humble/index.html
- **Computer Vision**: https://opencv.org/university/
- **Deep Learning**: https://pytorch.org/tutorials/
- **Robotics**: https://www.coursera.org/specializations/modernrobotics

**KsiÄ…Å¼ki**:
- "Programming Robots with ROS" - Morgan Quigley
- "Modern Robotics" - Kevin Lynch
- "Computer Vision: Algorithms and Applications" - Richard Szeliski

## ğŸ’¬ Pomoc i Wsparcie

### Q: Gdzie mogÄ™ zadaÄ‡ pytanie?

1. **GitHub Issues**: OtwÃ³rz issue z opisem problemu
2. **ROS Answers**: https://answers.ros.org/
3. **Stack Overflow**: Tag `ros2` lub `moveit`
4. **Discord/Slack**: SprawdÅº czy jest spoÅ‚ecznoÅ›Ä‡ projektu

### Q: Jak zgÅ‚osiÄ‡ bÅ‚Ä…d?

**Szablon zgÅ‚oszenia**:
```markdown
## Opis problemu
[KrÃ³tki opis co nie dziaÅ‚a]

## Kroki do reprodukcji
1. Uruchom...
2. Wykonaj...
3. Zaobserwuj...

## Oczekiwane zachowanie
[Co powinno siÄ™ staÄ‡]

## Aktualne zachowanie
[Co siÄ™ dzieje]

## Logi
```bash
[Wklej logi z terminala]
```

## Åšrodowisko
- Ubuntu: 22.04
- ROS 2: Humble
- Python: 3.10
- GPU: NVIDIA RTX 3060
```

---

**Nie znalazÅ‚eÅ› odpowiedzi?** OtwÃ³rz Issue na GitHubie z dokÅ‚adnym opisem problemu!
