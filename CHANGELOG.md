# ğŸ“ Historia Zmian (Changelog)

Wszystkie istotne zmiany w tym projekcie bÄ™dÄ… dokumentowane w tym pliku.

Format oparty na [Keep a Changelog](https://keepachangelog.com/pl/1.0.0/),
projekt przestrzega [Semantic Versioning](https://semver.org/lang/pl/).

---

## [1.0.0] - 2026-02-07

### ğŸ‰ Pierwsze Oficjalne Wydanie

To jest pierwsze stabilne wydanie systemu Robot G1 Handover - edukacyjnej platformy do nauki interakcji czÅ‚owiek-robot.

### âœ¨ Nowe Funkcje (Added)

#### Percepcja (Perception)
- **Detekcja obiektÃ³w 2D** z wykorzystaniem YOLOv5
  - ObsÅ‚uga 80 klas obiektÃ³w z zestawu COCO
  - Konfigurowalne progi pewnoÅ›ci (domyÅ›lnie 0.6)
  - WydajnoÅ›Ä‡: 15-30 FPS na GPU
- **Estymacja pozy 6D** obiektÃ³w w przestrzeni 3D
  - Model pinhole camera z mapÄ… gÅ‚Ä™bokoÅ›ci
  - DokÅ‚adnoÅ›Ä‡: Â±2cm
- **Statyczna transformacja kamery** (static_tf_camera.py)
  - Definiuje relacjÄ™ spatial kamery wzglÄ™dem bazy robota
- **Szkielet detekcji dÅ‚oni** (human_hand_detector.py)
  - Przygotowany do integracji z MediaPipe

#### Manipulacja (Manipulation)
- **Interfejs MoveIt 2** (moveit_interface.py)
  - Planowanie trajektorii bez kolizji
  - Konfigurowalny planner (domyÅ›lnie: RRTConnect)
  - Timeout planowania: 5s (konfigurowalny do 15s)
- **Planer chwytania** (grasp_planner.py)
  - Oblicza pozycje pre-grasp i grasp
  - Parametry: approach_distance, lift_distance
- **Planer przekazywania** (handover_planner.py)
  - Oblicza bezpiecznÄ… pozycjÄ™ do przekazania obiektu czÅ‚owiekowi
- **Wykonanie chwytania** (execute_grasp.py)
  - Sekwencja: approach â†’ grasp â†’ lift
  - Kontrola gripper: otwarcie/zamkniÄ™cie
- **Wykonanie handover** (execute_handover.py)
  - Sekwencja: move_to_human â†’ wait â†’ release
- **Scena planowania** (planning_scene.py)
  - Dodaje przeszkody (stÃ³Å‚, czÅ‚owiek) do MoveIt

#### Decyzje (Decision Making)
- **World Model AI Manager** (wma_handover_manager.py)
  - Integracja z UnifoLM-WMA (opcjonalna)
  - Przewidywanie intencji czÅ‚owieka
  - Automatyczne przeÅ‚Ä…czanie na mock mode jeÅ›li WMA niedostÄ™pny
- **Task Manager FSM** (wma_task_manager.py)
  - Automat stanÃ³w: IDLE â†’ TAKE_FROM_HUMAN â†’ HOLD â†’ GIVE_TO_HUMAN â†’ IDLE
  - ZarzÄ…dzanie przejÅ›ciami miÄ™dzy stanami

#### Launch Files
- **full_pipeline.launch.py** - Podstawowy pipeline percepcja + manipulacja
- **full_handover_pipeline.launch.py** - Kompletny system z WMA
- **launch_perception.launch.py** - Tylko moduÅ‚y percepcji

#### Konfiguracja
- **grasp_params.yaml** - Parametry chwytania
  - approach_distance: 0.10m
  - lift_distance: 0.15m
  - gripper_open/closed: 0.04m / 0.0m
  - max_force: 30.0N
- **moveit.yaml** - Parametry MoveIt 2
  - Planner: RRTConnect
  - Range: 0.3

### ğŸ“š Dokumentacja (Added)

#### Dokumentacja GÅ‚Ã³wna
- **README.md** - Kompletny przewodnik projektu (791 linii)
  - Szybki start w 5 minut
  - SzczegÃ³Å‚owa instalacja krok po kroku
  - Architektura systemu z diagramami ASCII
  - Status komponentÃ³w
  - FAQ z najczÄ™stszymi problemami
- **QUICK_START.md** - Ekspresowa Å›cieÅ¼ka uruchomienia
- **STATUS.md** - Dashboard statusu systemu
- **CHECKLIST.md** - Lista kontrolna dla uÅ¼ytkownikÃ³w

#### Tutoriale i Przewodniki
- **TUTORIALS.md** - SzczegÃ³Å‚owe tutoriale dla studentÃ³w
  - Tutorial 1: Percepcja wizualna
  - Tutorial 2: Planowanie ruchu z MoveIt 2
  - Tutorial 3: Integracja World Model AI
- **EXAMPLES.md** - Gotowe przykÅ‚ady kodu do skopiowania
- **QUICK_REFERENCE.md** - Szybka Å›ciÄ…ga z komendami

#### RozwiÄ…zywanie ProblemÃ³w
- **TROUBLESHOOTING.md** - Flowchart diagnostyki problemÃ³w
- **FAQ.md** - 20+ najczÄ™Å›ciej zadawanych pytaÅ„

#### Dokumentacja Techniczna
- **ARCHITECTURE.md** - SzczegÃ³Å‚owa architektura systemu
- **TESTING.md** - Strategia testowania
- **CONTRIBUTING.md** - Przewodnik dla kontrybutorÃ³w
- **GLOSSARY.md** - SÅ‚ownik 50+ terminÃ³w robotyki
- **IMPROVEMENT_SUMMARY.md** - Podsumowanie ulepszeÅ„ UX
- **UX_IMPROVEMENTS_SUMMARY.md** - Quality of Life features

### ğŸ”§ Wymagania Systemowe

#### System Operacyjny
- Ubuntu 22.04 LTS (wymagane)
- Co najmniej 4GB RAM
- ~10GB wolnego miejsca na dysku

#### Oprogramowanie
- ROS 2 Humble lub nowszy
- Python 3.10+
- MoveIt 2 (ros-humble-moveit)

#### Biblioteki Python (requirements.txt)
- PyTorch â‰¥ 1.10.0
- torchvision â‰¥ 0.11.0
- opencv-python â‰¥ 4.5.0
- numpy â‰¥ 1.21.0
- ultralytics (YOLOv5)
- mediapipe (opcjonalny)

#### SprzÄ™t (Opcjonalny)
- Intel RealSense D435 (kamera RGB-D)
- Unitree G1 Robot (lub symulator)
- GPU NVIDIA (zalecane dla YOLOv5)

### ğŸ¯ FunkcjonalnoÅ›ci dla StudentÃ³w

#### Nauka ROS 2
- PrzykÅ‚ady tworzenia node'Ã³w
- Komunikacja przez topiki
- Transformacje TF2
- Launch files i parametry

#### Nauka Computer Vision
- Wykrywanie obiektÃ³w z YOLO
- Estymacja pozy 3D/6D
- Kalibracja kamery
- Przetwarzanie obrazÃ³w RGB-D

#### Nauka Planowania Ruchu
- MoveIt 2 interface
- RRT path planning
- Collision avoidance
- Inverse kinematics

#### Nauka AI w Robotyce
- World Model Architecture
- State machines (FSM)
- Decision making
- Integracja modeli PyTorch

### ğŸ› Znane Ograniczenia (Known Issues)

1. **Detekcja dÅ‚oni** - Wymaga integracji MediaPipe (obecnie placeholder)
2. **World Model AI** - Wymaga checkpointu modelu (dziaÅ‚a mock mode)
3. **Testy jednostkowe** - W trakcie implementacji
4. **Wsparcie symulacji** - Wymaga Gazebo/MuJoCo setup
5. **Dokumentacja API** - Brak automatycznych docstrings

### ğŸ”’ BezpieczeÅ„stwo (Security)

- System przeznaczony **wyÅ‚Ä…cznie do celÃ³w edukacyjnych**
- **OstrzeÅ¼enie**: Przed uÅ¼yciem na prawdziwym robocie naleÅ¼y:
  - DokÅ‚adnie przetestowaÄ‡ w symulacji
  - ZaimplementowaÄ‡ safety limits
  - DodaÄ‡ emergency stop
  - PrzeprowadziÄ‡ risk assessment

### ğŸ“¦ Dystrybucja

- **Repozytorium GitHub**: https://github.com/MatPomGit/robot-g1-Handover
- **Licencja**: MIT (open source)
- **JÄ™zyk**: Python + ROS 2
- **Platforma**: Ubuntu 22.04 + ROS 2 Humble

### ğŸ‘¥ Autorzy

- Robot G1 Handover Team
- Kontakt: contact@robotg1handover.org

### ğŸ™ PodziÄ™kowania (Credits)

Ten projekt wykorzystuje nastÄ™pujÄ…ce narzÄ™dzia open-source:
- **ROS 2 Humble** - Robot Operating System
- **MoveIt 2** - Motion planning framework
- **YOLOv5** (Ultralytics) - Object detection
- **PyTorch** - Deep learning framework
- **OpenCV** - Computer vision library
- **Intel RealSense SDK** - Camera drivers
- **Unitree Robotics** - G1 robot model

---

## [0.1.0] - 2024-XX-XX

### ğŸŒ± Wersja PoczÄ…tkowa (Initial Development)

- Prototyp systemu
- Podstawowa struktura moduÅ‚Ã³w
- Wczesne testy koncepcyjne

---

## Konwencje Changelogu

### Typy zmian:
- **Added** (âœ¨ Nowe funkcje) - Nowe funkcjonalnoÅ›ci
- **Changed** (ğŸ”„ Zmiany) - Zmiany w istniejÄ…cych funkcjonalnoÅ›ciach
- **Deprecated** (âš ï¸ PrzestarzaÅ‚e) - Funkcje do usuniÄ™cia w przyszÅ‚oÅ›ci
- **Removed** (ğŸ—‘ï¸ UsuniÄ™te) - UsuniÄ™te funkcjonalnoÅ›ci
- **Fixed** (ğŸ› Naprawione) - Poprawki bÅ‚Ä™dÃ³w
- **Security** (ğŸ”’ BezpieczeÅ„stwo) - Poprawki bezpieczeÅ„stwa

### Format wersji (Semantic Versioning):
- **MAJOR.MINOR.PATCH** (np. 1.0.0)
  - **MAJOR** - Niekompatybilne zmiany API
  - **MINOR** - Nowe funkcje (kompatybilne wstecz)
  - **PATCH** - Poprawki bÅ‚Ä™dÃ³w (kompatybilne wstecz)

---

**[Unreleased]** - NadchodzÄ…ce zmiany (do nastÄ™pnej wersji)

### Planowane na 1.1.0
- [ ] Integracja MediaPipe dla detekcji dÅ‚oni
- [ ] Testy jednostkowe (pytest)
- [ ] Wsparcie dla Gazebo simulation
- [ ] Docker container
- [ ] CI/CD pipeline (GitHub Actions)
- [ ] Automatic API documentation (Sphinx)

### Planowane na 2.0.0
- [ ] Wsparcie dla wielu robotÃ³w
- [ ] Web-based monitoring dashboard
- [ ] Real-time 3D visualization
- [ ] Advanced safety features
- [ ] Multi-language support (English docs)

---

## Linki

- **Repository**: https://github.com/MatPomGit/robot-g1-Handover
- **Issues**: https://github.com/MatPomGit/robot-g1-Handover/issues
- **Dokumentacja**: Patrz README.md i pliki dokumentacji

---

<div align="center">

**DziÄ™kujemy za korzystanie z Robot G1 Handover System!** ğŸ¤–â¤ï¸

</div>
