# ModuÅ‚ Percepcji (Perception Module)

## ğŸ“– Wprowadzenie

ModuÅ‚ percepcji odpowiada za rozumienie otoczenia robota poprzez przetwarzanie danych z kamer i czujnikÃ³w. Jest to "oko" robota, ktÃ³re pozwala mu zobaczyÄ‡ i zrozumieÄ‡ co siÄ™ dzieje w jego otoczeniu.

## ğŸ¯ Funkcje ModuÅ‚u

### 1. **Wykrywanie ObiektÃ³w** (`object_detector.py`)
- UÅ¼ywa sieci neuronowej YOLOv5 do detekcji obiektÃ³w
- Wykrywa 80 klas obiektÃ³w (COCO dataset)
- Zwraca bounding boxes (prostokÄ…ty) wokÃ³Å‚ obiektÃ³w
- DziaÅ‚a w czasie rzeczywistym (~30 FPS)

### 2. **Estymacja Pozy 6D** (`pose_estimator_6d.py`)
- Konwertuje detekcje 2D na pozycje 3D
- UÅ¼ywa mapy gÅ‚Ä™bokoÅ›ci z kamery RGB-D
- Stosuje pinhole camera model
- Zwraca pozycjÄ™ (x, y, z) obiektÃ³w w przestrzeni

### 3. **Detekcja DÅ‚oni CzÅ‚owieka** (`human_hand_detector.py`)
- Wykrywa pozycjÄ™ dÅ‚oni czÅ‚owieka w 3D
- OkreÅ›la intencjÄ™ czÅ‚owieka (czy wyciÄ…ga rÄ™kÄ™)
- MoÅ¼e uÅ¼ywaÄ‡ MediaPipe lub OpenPose
- Kluczowe dla interakcji czÅ‚owiek-robot

### 4. **Transformacje TF** (`static_tf_camera.py`)
- Definiuje pozycjÄ™ kamery wzglÄ™dem robota
- Publikuje statycznÄ… transformacjÄ™ base_link -> camera_link
- UmoÅ¼liwia konwersjÄ™ wspÃ³Å‚rzÄ™dnych miÄ™dzy ukÅ‚adami

## ğŸ“Š PrzepÅ‚yw Danych

```
Kamera RGB-D
    |
    +---> [Object Detector] ---> /object_detections
    |           |
    |           v
    +---> [Pose Estimator 6D] ---> /object_pose
    |
    +---> [Human Hand Detector] ---> /human_hand_pose
                                      /human_reaching
```

## ğŸ”§ Topiki ROS 2

### Subskrybowane (Input):
- `/camera/color/image_raw` - Obraz RGB z kamery
- `/camera/depth/image_raw` - Mapa gÅ‚Ä™bokoÅ›ci z kamery
- `/camera/color/camera_info` - Parametry kalibracji kamery

### Publikowane (Output):
- `/object_detections` - Wykryte obiekty (Detection2DArray)
- `/object_pose` - Pozycja 3D obiektu (PoseStamped)
- `/human_hand_pose` - Pozycja dÅ‚oni czÅ‚owieka (PoseStamped)
- `/human_reaching` - Intencja czÅ‚owieka (Bool)
- `/tf_static` - Transformacja kamery (TFMessage)

## ğŸš€ UÅ¼ycie

### Uruchomienie wszystkich komponentÃ³w percepcji:

```bash
# Terminal 1: Statyczna transformacja kamery
ros2 run g1_pick_and_handover static_tf_camera

# Terminal 2: Detektor obiektÃ³w
ros2 run g1_pick_and_handover object_detector

# Terminal 3: Estymator pozy 6D
ros2 run g1_pick_and_handover pose_estimator_6d

# Terminal 4: Detektor dÅ‚oni
ros2 run g1_pick_and_handover human_hand_detector
```

### Sprawdzanie wynikÃ³w:

```bash
# Zobacz wykryte obiekty
ros2 topic echo /object_detections

# Zobacz pozycjÄ™ 3D obiektu
ros2 topic echo /object_pose

# Zobacz pozycjÄ™ dÅ‚oni czÅ‚owieka
ros2 topic echo /human_hand_pose
```

## ğŸ“š Kluczowe Algorytmy

### YOLOv5 (You Only Look Once v5)
- Szybki detektor obiektÃ³w w czasie rzeczywistym
- Single-stage detector (jedna sieÄ‡ neuronowa)
- Wersje: yolov5s (small, szybka), yolov5m, yolov5l, yolov5x (duÅ¼a, dokÅ‚adna)
- Pretrenowany na COCO dataset (80 klas)

### Pinhole Camera Model
Konwersja 2D (piksele) -> 3D (metry):
```
x = (u - cx) * z / fx
y = (v - cy) * z / fy
```
gdzie:
- (u, v) = pozycja piksela
- (cx, cy) = optyczny Å›rodek kamery
- (fx, fy) = ogniskowe kamery
- z = gÅ‚Ä™bokoÅ›Ä‡
- (x, y, z) = pozycja 3D

### MediaPipe Hand Tracking
- Wykrywa 21 kluczowych punktÃ³w dÅ‚oni
- DziaÅ‚a w czasie rzeczywistym
- ObsÅ‚uguje jednÄ… lub dwie rÄ™ce
- Zwraca pozycjÄ™ 2D i 3D landmarkÃ³w

## ğŸ› ï¸ Konfiguracja

### Wymagania:
```bash
# PyTorch (dla YOLOv5)
pip install torch torchvision

# OpenCV (przetwarzanie obrazu)
pip install opencv-python

# MediaPipe (detekcja dÅ‚oni)
pip install mediapipe

# ROS 2 packages
sudo apt install ros-humble-cv-bridge
sudo apt install ros-humble-vision-msgs
```

### Kamera RGB-D:
- Intel RealSense D435 (zalecane)
- Azure Kinect
- Lub inna kamera z depth sensing

## ğŸ” Debugowanie

### Problem: Brak detekcji obiektÃ³w
```bash
# SprawdÅº czy kamera dziaÅ‚a
ros2 topic echo /camera/color/image_raw

# SprawdÅº czy YOLOv5 siÄ™ zaÅ‚adowaÅ‚
ros2 node info /object_detector

# Zobacz logi
ros2 run g1_pick_and_handover object_detector --ros-args --log-level debug
```

### Problem: NieprawidÅ‚owa pozycja 3D
```bash
# SprawdÅº transformacjÄ™ TF
ros2 run tf2_ros tf2_echo base_link camera_link

# SprawdÅº parametry kalibracji
ros2 topic echo /camera/color/camera_info

# Wizualizuj w RViz
rviz2
```

### Problem: Nie wykrywa dÅ‚oni
- Upewnij siÄ™, Å¼e MediaPipe jest zainstalowany
- SprawdÅº oÅ›wietlenie (dÅ‚oÅ„ musi byÄ‡ dobrze oÅ›wietlona)
- ZwiÄ™ksz kontrast lub jasnoÅ›Ä‡ obrazu

## ğŸ“– Tutorial dla StudentÃ³w

### Ä†wiczenie 1: Zrozumienie YOLOv5

1. Uruchom detektor:
   ```bash
   ros2 run g1_pick_and_handover object_detector
   ```

2. PoÅ‚Ã³Å¼ rÃ³Å¼ne obiekty przed kamerÄ… (kubek, telefon, klawiatura)

3. Obserwuj detekcje:
   ```bash
   ros2 topic echo /object_detections
   ```

4. **Zadanie**: Zapisz, ktÃ³re obiekty YOLOv5 wykrywa najlepiej

### Ä†wiczenie 2: Estymacja Pozy 3D

1. Uruchom caÅ‚y pipeline percepcji

2. UmieÅ›Ä‡ obiekt w rÃ³Å¼nych pozycjach

3. Zapisuj pozycje 3D:
   ```bash
   ros2 topic echo /object_pose > positions.txt
   ```

4. **Zadanie**: Zmierz dokÅ‚adnoÅ›Ä‡ - porÃ³wnaj ze zmierzonÄ… taÅ›mÄ… odlegÅ‚oÅ›ciÄ…

### Ä†wiczenie 3: Wizualizacja w RViz

1. Uruchom RViz:
   ```bash
   rviz2
   ```

2. Dodaj displays:
   - Image: `/camera/color/image_raw`
   - TF: PokaÅ¼ transformacje
   - PoseStamped: `/object_pose`

3. **Zadanie**: Zaobserwuj jak pozycja obiektu zmienia siÄ™ w czasie rzeczywistym

## ğŸ”¬ Zaawansowane

### Modyfikacja progu pewnoÅ›ci YOLOv5:
W `object_detector.py`, zmieÅ„:
```python
if conf < 0.6:  # ZmieÅ„ 0.6 na innÄ… wartoÅ›Ä‡ (0.0-1.0)
```

### Dodanie nowej klasy obiektÃ³w:
- Wytrenuj custom YOLOv5 na wÅ‚asnym datasecie
- ZaÅ‚aduj custom weights zamiast pretrained

### Integracja z innymi detektorami:
- Faster R-CNN (dokÅ‚adniejszy, wolniejszy)
- EfficientDet (dobry kompromis)
- DETR (Transformer-based)

## ğŸ“š Dodatkowe Zasoby

- [YOLOv5 Documentation](https://github.com/ultralytics/yolov5)
- [MediaPipe Hand Tracking](https://google.github.io/mediapipe/solutions/hands.html)
- [ROS 2 CV Bridge Tutorial](https://docs.ros.org/en/humble/Tutorials/Advanced/CvBridge.html)
- [Camera Calibration](http://wiki.ros.org/camera_calibration)

---

**Pytania?** OtwÃ³rz Issue na GitHubie lub skonsultuj siÄ™ z prowadzÄ…cym!
