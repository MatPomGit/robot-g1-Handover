# ğŸ¤– Robot G1 - System Przekazywania ObiektÃ³w (Handover)

[![ROS 2](https://img.shields.io/badge/ROS_2-Humble-blue)](https://docs.ros.org/en/humble/)
[![Python](https://img.shields.io/badge/Python-3.10+-green)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-Open_Source-yellow)](LICENSE)

> **Edukacyjny system robotyki** demonstrujÄ…cy inteligentnÄ… interakcjÄ™ czÅ‚owiek-robot z wykorzystaniem percepcji wizyjnej, planowania ruchu i AI.

---

## ğŸš€ Szybki Start (Quick Start)

**Chcesz od razu zobaczyÄ‡ system w akcji? Skorzystaj z tego 5-minutowego przewodnika:**

```bash
# 1. Klonuj repozytorium
git clone https://github.com/MatPomGit/robot-g1-Handover.git
cd robot-g1-Handover

# 2. Zainstaluj zaleÅ¼noÅ›ci (wymaga Ubuntu 22.04 + ROS 2 Humble)
./scripts/quick_setup.sh

# 3. Uruchom demonstracjÄ™
ros2 launch g1_pick_and_handover full_handover_pipeline.launch.py

# 4. W osobnym terminalu - odtwÃ³rz wÅ‚asne dane z kamery (rosbag z odpowiednimi tematami)
ros2 bag play <twoj_plik_rosbag.bag> --loop
```

ğŸ“– **Pierwszy raz z ROS 2?** Zobacz [szczegÃ³Å‚owÄ… instrukcjÄ™ instalacji](#-instalacja) poniÅ¼ej.

---

## ğŸ’¡ Co robi ten system?

Ten projekt demonstruje system interakcji czÅ‚owiek-robot dla robota humanoidalnego **Unitree G1**. Robot moÅ¼e:

| Funkcja | Opis | Status |
|---------|------|--------|
| ğŸ¤ **Odbieranie obiektÃ³w** | Robot bierze przedmiot od czÅ‚owieka | âœ… DziaÅ‚a |
| ğŸ“¦ **Przekazywanie obiektÃ³w** | Robot podaje przedmiot czÅ‚owiekowi | âœ… DziaÅ‚a |
| ğŸ§  **Inteligentne decyzje** | AI przewiduje intencje czÅ‚owieka | âš ï¸ Wymaga WMA |
| ğŸ‘ï¸ **Percepcja wizualna** | Wykrywa obiekty i dÅ‚onie (YOLO + MediaPipe) | âœ… DziaÅ‚a |
| ğŸ¦¾ **Planowanie ruchu** | Bezpieczne trajektorie z MoveIt 2 | âœ… DziaÅ‚a |

### ğŸ“ Dla kogo?

- **Studenci robotyki** - naucz siÄ™ ROS 2, MoveIt 2, percepcji wizyjnej
- **Nauczyciele** - gotowy projekt do demonstracji HRI (Human-Robot Interaction)
- **Badacze** - platforma do eksperymentÃ³w z AI w robotyce
- **EntuzjaÅ›ci** - poznaj jak dziaÅ‚ajÄ… zaawansowane systemy robotyczne

---

## ğŸ“Š Jak to dziaÅ‚a? (Wizualny przeglÄ…d)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                       â”‚
â”‚  CZÅOWIEK wyciÄ…ga rÄ™kÄ™                    ROBOT wykrywa intencjÄ™    â”‚
â”‚      ğŸ‘¤ ğŸ¤š                                       ğŸ¤–                   â”‚
â”‚       â”‚                                          â†‘                   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   PERCEPCJA  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   DECYZJE    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  MANIPULACJA â”‚
          â”‚              â”‚         â”‚              â”‚         â”‚              â”‚
          â”‚ ğŸ‘ï¸ Kamery   â”‚         â”‚ ğŸ§  AI/WMA    â”‚         â”‚ ğŸ¦¾ MoveIt 2  â”‚
          â”‚ ğŸ¯ YOLO      â”‚         â”‚ ğŸ“‹ FSM       â”‚         â”‚ âœ‹ Gripper    â”‚
          â”‚ âœ‹ MediaPipe  â”‚         â”‚              â”‚         â”‚              â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“                         â†“                        â†“
          Wykrywa obiekty       Podejmuje decyzjÄ™          Wykonuje ruch
          i pozycjÄ™ dÅ‚oni       (BraÄ‡/DaÄ‡/CzekaÄ‡)         bezkolizyjnie
```

**PrzykÅ‚adowy przepÅ‚yw:**
1. ğŸ‘ï¸ Kamera widzi czÅ‚owieka wyciÄ…gajÄ…cego rÄ™kÄ™ z kubkiem
2. ğŸ¯ YOLO wykrywa kubek, MediaPipe wykrywa dÅ‚oÅ„
3. ğŸ§  AI decyduje: "CzÅ‚owiek chce mi daÄ‡ kubek" â†’ TAKE_FROM_HUMAN
4. ğŸ¦¾ Robot planuje trajektoriÄ™ i podjeÅ¼dÅ¼a do dÅ‚oni
5. âœ‹ Gripper chwyta kubek, robot go podnosi

---

## ğŸ¯ Architektura Systemu

<details>
<summary><b>ğŸ“‚ Kliknij aby zobaczyÄ‡ szczegÃ³Å‚owÄ… architekturÄ™</b></summary>

System skÅ‚ada siÄ™ z czterech gÅ‚Ã³wnych moduÅ‚Ã³w:

### 1. ğŸ“¸ **Perception (Percepcja)**
Odpowiada za rozumienie otoczenia robota poprzez kamery i czujniki.

**Pliki:**
- `human_hand_detector.py` - Wykrywa pozycjÄ™ dÅ‚oni czÅ‚owieka w przestrzeni 3D
- `object_detector.py` - Wykrywa obiekty na obrazie z kamery (uÅ¼ywa YOLOv5)
- `pose_estimator_6d.py` - Oblicza pozÄ™ 6D obiektÃ³w (pozycja x,y,z + orientacja)
- `static_tf_camera.py` - Definiuje transformacjÄ™ kamery wzglÄ™dem bazy robota

**Jak to dziaÅ‚a:**
1. Kamera RGB-D rejestruje obraz kolorowy i mapÄ™ gÅ‚Ä™bokoÅ›ci
2. YOLOv5 wykrywa obiekty na obrazie RGB
3. UÅ¼ywajÄ…c mapy gÅ‚Ä™bokoÅ›ci, system oblicza pozycjÄ™ 3D obiektu
4. MediaPipe/OpenPose wykrywa kluczowe punkty dÅ‚oni czÅ‚owieka

### 2. ğŸ¦¾ **Manipulation (Manipulacja)**
Odpowiada za planowanie i wykonywanie ruchÃ³w ramienia robota.

**Pliki:**
- `moveit_interface.py` - Interface do MoveIt 2 (planowanie trajektorii)
- `handover_planner.py` - Oblicza pozycjÄ™ do przekazania obiektu
- `grasp_planner.py` - Oblicza pozycjÄ™ pre-grasp przedchwyceniem
- `execute_grasp.py` - Wykonuje sekwencjÄ™ chwytania obiektu
- `execute_handover.py` - Wykonuje sekwencjÄ™ przekazywania obiektu
- `planning_scene.py` - Dodaje przeszkody (stÃ³Å‚, czÅ‚owiek) do sceny planowania

**Jak to dziaÅ‚a:**
1. MoveIt 2 planuje trajektoriÄ™ ruchu ramienia bez kolizji
2. System oblicza pozycje poÅ›rednie (pre-grasp, grasp, handover)
3. Gripper (chwytak) otwiera siÄ™ i zamyka w odpowiednich momentach
4. Robot wykonuje ruch pÅ‚ynnie i bezpiecznie

### 3. ğŸ§  **Decision (Decyzje)**
Wykorzystuje sztucznÄ… inteligencjÄ™ do podejmowania decyzji o akcjach robota.

**Pliki:**
- `wma_handover_manager.py` - Manager decyzji WMA dla przekazywania obiektÃ³w
- `wma_task_manager.py` - Manager stanÃ³w automatu skoÅ„czonego (FSM)

**Jak to dziaÅ‚a:**
1. World Model AI (WMA) analizuje obserwacje z kamer i czujnikÃ³w
2. WMA przewiduje intencje czÅ‚owieka (czy chce daÄ‡/wziÄ…Ä‡ obiekt)
3. System podejmuje decyzjÄ™: TAKE_FROM_HUMAN, GIVE_TO_HUMAN lub IDLE
4. FSM (Finite State Machine) zarzÄ…dza przejÅ›ciami miÄ™dzy stanami

### 4. ğŸš€ **Launch**
Pliki uruchomieniowe, ktÃ³re startujÄ… wszystkie komponenty systemu.

**Pliki:**
- `full_pipeline.launch.py` - Uruchamia podstawowy pipeline
- `full_handover_pipeline.launch.py` - Uruchamia kompletny system handover

</details>

---

## ğŸ”§ Instalacja

### âš¡ Ekspresowa instalacja (Dla doÅ›wiadczonych uÅ¼ytkownikÃ³w ROS 2)

JeÅ›li masz juÅ¼ **Ubuntu 22.04 + ROS 2 Humble + MoveIt 2**, wystarczy:

```bash
# Sklonuj i zbuduj
git clone https://github.com/MatPomGit/robot-g1-Handover.git ~/ros2_ws/src/robot-g1-Handover
cd ~/ros2_ws
rosdep install --from-paths src --ignore-src -r -y
pip3 install -r src/robot-g1-Handover/requirements.txt
colcon build --packages-select g1_pick_and_handover
source install/setup.bash

# Gotowe! ğŸ‰
```

### ğŸ“š SzczegÃ³Å‚owa instalacja (Krok po kroku)

<details>
<summary><b>ğŸ‘† Kliknij tutaj jeÅ›li instalujesz po raz pierwszy</b></summary>

#### Wymagania wstÄ™pne

| Wymaganie | Wersja | Sprawdzenie |
|-----------|--------|-------------|
| Ubuntu | 22.04 LTS | `lsb_release -a` |
| ROS 2 | Humble+ | `ros2 --version` |
| Python | 3.10+ | `python3 --version` |
| MoveIt 2 | Humble | `ros2 pkg list \| grep moveit` |

#### Krok 1: Instalacja ROS 2 Humble

```bash
# Dodaj repozytorium ROS 2
sudo apt update && sudo apt install software-properties-common
sudo add-apt-repository universe
sudo apt update && sudo apt install curl -y
sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg

# Dodaj ÅºrÃ³dÅ‚a ROS 2
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release && echo $UBUNTU_CODENAME) main" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null

# Zainstaluj ROS 2 Humble
sudo apt update
sudo apt install ros-humble-desktop
```

### Krok 2: Instalacja MoveIt 2

```bash
sudo apt install ros-humble-moveit
```

### Krok 3: Instalacja zaleÅ¼noÅ›ci Python

```bash
# Zainstaluj pip jeÅ›li nie masz
sudo apt install python3-pip

# Zainstaluj wymagane pakiety z pliku requirements.txt
pip3 install -r requirements.txt
```

âš ï¸ **Uwaga:** JeÅ›li masz GPU NVIDIA, zainstaluj PyTorch z CUDA dla lepszej wydajnoÅ›ci YOLO:
```bash
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Krok 4: Klonowanie i konfiguracja workspace

```bash
# UtwÃ³rz workspace ROS 2
mkdir -p ~/ros2_ws/src
cd ~/ros2_ws/src

# Sklonuj to repozytorium
git clone https://github.com/MatPomGit/robot-g1-Handover.git

# Zainstaluj zaleÅ¼noÅ›ci ROS 2
cd ~/ros2_ws
rosdep install --from-paths src --ignore-src -r -y

# Zbuduj workspace
colcon build
source install/setup.bash
```

### Krok 5: Konfiguracja modelu robota G1

```bash
# Pobierz opis robota Unitree G1
cd ~/ros2_ws/src
git clone https://github.com/unitreerobotics/unitree_ros.git
cd ~/ros2_ws
colcon build --packages-select g1_description
```

âœ… **Gratulacje!** Instalacja zakoÅ„czona. PrzejdÅº do sekcji [UÅ¼ycie](#-uÅ¼ycie).

</details>

---

## ğŸ® UÅ¼ycie

### ğŸš¦ Opcja 1: Uruchomienie kompletnego systemu (Zalecane)

```bash
# TERMINAL 1: Uruchom gÅ‚Ã³wny system
cd ~/ros2_ws
source install/setup.bash
ros2 launch g1_pick_and_handover full_handover_pipeline.launch.py
```

ğŸ‰ **System uruchomiony!** Zobaczysz logi poszczegÃ³lnych moduÅ‚Ã³w.

### ğŸ§ª Opcja 2: Uruchomienie w trybie testowym (bez fizycznego robota)

```bash
# TERMINAL 1: Symuluj dane z kamery
ros2 bag play test_data.bag --loop

# TERMINAL 2: Uruchom system
ros2 launch g1_pick_and_handover full_handover_pipeline.launch.py

# TERMINAL 3: Wizualizacja w RViz
rviz2
```

### ğŸ” Opcja 3: Uruchomienie poszczegÃ³lnych komponentÃ³w (Debug)

<details>
<summary><b>ğŸ“¦ Kliknij aby zobaczyÄ‡ komponenty do uruchomienia osobno</b></summary>

#### 1. Tylko percepcja (wykrywanie obiektÃ³w i dÅ‚oni)

```bash
# Terminal 1: Detekcja obiektÃ³w
ros2 run g1_pick_and_handover object_detector

# Terminal 2: Estymacja pozy 6D
ros2 run g1_pick_and_handover pose_estimator_6d

# Terminal 3: Detekcja dÅ‚oni czÅ‚owieka
ros2 run g1_pick_and_handover human_hand_detector
```

#### 2. Tylko manipulacja (test ruchu ramienia)

```bash
# Uruchom interfejs MoveIt
ros2 run g1_pick_and_handover moveit_interface
```

#### 3. System decyzyjny z WMA

```bash
ros2 run g1_pick_and_handover execute_handover_wma
```

</details>

---

## ğŸ“Š PrzepÅ‚yw Danych (Topics ROS 2)

System komunikuje siÄ™ poprzez nastÄ™pujÄ…ce topiki ROS 2:

| Topic | Typ | Opis |
|-------|-----|------|
| `/camera/color/image_raw` | `sensor_msgs/Image` | Obraz RGB z kamery |
| `/camera/depth/image_raw` | `sensor_msgs/Image` | Mapa gÅ‚Ä™bokoÅ›ci z kamery |
| `/camera/color/camera_info` | `sensor_msgs/CameraInfo` | Kalibracja kamery |
| `/object_detections` | `vision_msgs/Detection2DArray` | Wykryte obiekty (2D bounding boxes) |
| `/object_pose` | `geometry_msgs/PoseStamped` | Pozycja 3D obiektu |
| `/human_hand_pose` | `geometry_msgs/PoseStamped` | Pozycja dÅ‚oni czÅ‚owieka |
| `/human_reaching` | `std_msgs/Bool` | Czy czÅ‚owiek wyciÄ…ga rÄ™kÄ™ |
| `/gripper_state` | `std_msgs/Bool` | Stan chwytaka (otwarty/zamkniÄ™ty) |

## ğŸ”„ Automat StanÃ³w (FSM)

System dziaÅ‚a wedÅ‚ug nastÄ™pujÄ…cego automatu stanÃ³w:

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     IDLE      â”‚  â† Stan poczÄ…tkowy
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
    human_reaching=True
    gripper_occupied=False
                â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  TAKE_FROM_HUMAN   â”‚  â† Robot podjeÅ¼dÅ¼a do dÅ‚oni czÅ‚owieka
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
gripper_closed=True
            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     HOLD      â”‚  â† Robot trzyma obiekt
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
human_reaching=True
gripper_occupied=True
                â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  GIVE_TO_HUMAN     â”‚  â† Robot przekazuje obiekt czÅ‚owiekowi
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
gripper_open=True
            â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     IDLE      â”‚  â† PowrÃ³t do stanu poczÄ…tkowego
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Tutoriale dla StudentÃ³w

### Tutorial 1: Zrozumienie percepcji wizyjnej

1. Uruchom detektor obiektÃ³w:
   ```bash
   ros2 run g1_pick_and_handover object_detector
   ```

2. Obserwuj wykryte obiekty:
   ```bash
   ros2 topic echo /object_detections
   ```

3. **Zadanie**: PoÅ‚Ã³Å¼ rÃ³Å¼ne obiekty przed kamerÄ… i obserwuj, jak system je wykrywa.

### Tutorial 2: Planowanie ruchu z MoveIt 2

1. Uruchom MoveIt 2 w trybie wizualizacji:
   ```bash
   ros2 launch moveit2_tutorials demo.launch.py
   ```

2. **Zadanie**: UÅ¼ywajÄ…c RViz, zaplanuj trajektoriÄ™ ruchu ramienia do rÃ³Å¼nych pozycji.

### Tutorial 3: Integracja WMA

1. Przestudiuj plik `wma_handover_manager.py`
2. Zrozum, jak obserwacje sÄ… przeksztaÅ‚cane w tensory PyTorch
3. **Zadanie**: Dodaj nowÄ… obserwacjÄ™ (np. kolor obiektu) do systemu WMA

## ğŸ“ Struktura KatalogÃ³w

```
robot-g1-Handover/
â”œâ”€â”€ README.md                    # Ten plik
â”œâ”€â”€ CONTRIBUTING.md              # Przewodnik dla kontrybutorÃ³w
â”œâ”€â”€ requirements.txt             # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ package.xml                  # Deskryptor pakietu ROS 2
â”œâ”€â”€ setup.py                     # Konfiguracja instalacji Python
â”œâ”€â”€ setup.cfg                    # Konfiguracja setuptools
â”œâ”€â”€ perception/                  # ModuÅ‚ percepcji
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ human_hand_detector.py
â”‚   â”œâ”€â”€ object_detector.py
â”‚   â”œâ”€â”€ pose_estimator_6d.py
â”‚   â””â”€â”€ static_tf_camera.py
â”œâ”€â”€ manipulation/                # ModuÅ‚ manipulacji
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ moveit_interface.py
â”‚   â”œâ”€â”€ handover_planner.py
â”‚   â”œâ”€â”€ grasp_planner.py
â”‚   â”œâ”€â”€ execute_grasp.py
â”‚   â”œâ”€â”€ execute_handover.py
â”‚   â””â”€â”€ planning_scene.py
â”œâ”€â”€ decision/                    # ModuÅ‚ decyzyjny
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ wma_handover_manager.py
â”‚   â””â”€â”€ wma_task_manager.py
â”œâ”€â”€ launch/                      # Pliki uruchomieniowe
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ full_pipeline.launch.py
â”‚   â”œâ”€â”€ full_handover_pipeline.launch.py
â”‚   â””â”€â”€ launch_perception.launch.py
â””â”€â”€ config/                      # Pliki konfiguracyjne
    â”œâ”€â”€ README.md
    â”œâ”€â”€ grasp_params.yaml
    â””â”€â”€ moveit.yaml
```

## ğŸ” Wizualizacja z MuJoCo

Aby zwizualizowaÄ‡ robota G1 w symulatorze:

```bash
# Zainstaluj MuJoCo
pip install mujoco

# Uruchom viewer
python -m mujoco.viewer

# PrzeciÄ…gnij plik MJCF/URDF modelu G1 do okna viewera
# Pliki modeli: https://github.com/unitreerobotics/unitree_ros/tree/master/robots/g1_description
```

## ğŸ› ï¸ Konfiguracja

### Parametry chwytania (grasp_params.yaml)

- `approach_distance`: OdlegÅ‚oÅ›Ä‡ podejÅ›cia przed chwyceniem (0.10m)
- `lift_distance`: WysokoÅ›Ä‡ podniesienia pochwyceniu (0.15m)
- `gripper_open`: Otwarcie chwytaka (0.04m)
- `gripper_closed`: ZamkniÄ™cie chwytaka (0.0m)
- `max_force`: Maksymalna siÅ‚a chwytaka (30.0N)

### Parametry MoveIt 2 (moveit.yaml)

- Planner: RRTConnect (algorytm planowania trajektorii)
- Range: 0.3 (zakres prÃ³bkowania dla RRT)

---

## â“ NajczÄ™stsze pytania (Quick FAQ)

<details>
<summary><b>âŒ System nie uruchamia siÄ™ - co robiÄ‡?</b></summary>

**Kroki diagnozy:**
1. SprawdÅº czy ROS 2 jest zainstalowany: `ros2 --version`
2. Source workspace: `source ~/ros2_ws/install/setup.bash`
3. SprawdÅº pakiet: `ros2 pkg list | grep g1_pick_and_handover`
4. Zobacz szczegÃ³Å‚y: [TROUBLESHOOTING.md](TROUBLESHOOTING.md)

</details>

<details>
<summary><b>ğŸ“· Kamera nie dziaÅ‚a - jak naprawiÄ‡?</b></summary>

**Szybkie rozwiÄ…zania:**
1. Fizyczna kamera: `ros2 run realsense2_camera realsense2_camera_node`
2. Bez kamery: UÅ¼yj bag file `ros2 bag play test_data.bag --loop`
3. Zobacz: [TROUBLESHOOTING.md](TROUBLESHOOTING.md#-problem-brak-kamery)

</details>

<details>
<summary><b>ğŸ¯ YOLO nie wykrywa obiektÃ³w - dlaczego?</b></summary>

**SprawdÅº:**
- Czy obiekt jest w zbiorze COCO (80 klas)?
- ObniÅ¼ prÃ³g: `--ros-args -p confidence_threshold:=0.3`
- WiÄ™kszy model: `-p model_name:=yolov5m`
- Zobacz: [FAQ.md](FAQ.md#q-yolov5-nie-wykrywa-obiektÃ³w)

</details>

<details>
<summary><b>âš ï¸ "WMA not available" - czy to bÅ‚Ä…d?</b></summary>

**NIE, to normalne!** ğŸ‰

System automatycznie uÅ¼ywa prostego trybu decyzyjnego (if-else), ktÃ³ry dziaÅ‚a Å›wietnie do nauki i testÃ³w. WMA jest opcjonalny i zaawansowany. Zobacz: [FAQ.md](FAQ.md#q-wma-nie-jest-dostÄ™pny)

</details>

<details>
<summary><b>ğŸ¦¾ MoveIt nie planuje - co sprawdziÄ‡?</b></summary>

**Checklist:**
- [ ] Cel w zasiÄ™gu? (0.3-0.8m dla G1)
- [ ] ZwiÄ™ksz timeout: `self.arm.set_planning_time(15.0)`
- [ ] ZwiÄ™ksz tolerancjÄ™: `self.arm.set_goal_position_tolerance(0.01)`
- [ ] Zobacz: [FAQ.md](FAQ.md#q-moveit-2-nie-planuje-trajektorii)

</details>

**WiÄ™cej pytaÅ„?** Zobacz peÅ‚ne [FAQ.md](FAQ.md)

---

## ğŸ› RozwiÄ…zywanie problemÃ³w

### âš¡ Szybkie rozwiÄ…zania najczÄ™stszych problemÃ³w

<details>
<summary><b>âŒ BÅ‚Ä…d: "package not found" podczas budowania</b></summary>

**Problem:** `colcon build` nie znajduje zaleÅ¼noÅ›ci.

**RozwiÄ…zanie:**
```bash
cd ~/ros2_ws
rosdep update
rosdep install --from-paths src --ignore-src -r -y
colcon build --symlink-install
```

**SprawdÅº czy pomogÅ‚o:**
```bash
ros2 pkg list | grep g1_pick_and_handover
# Powinno wyÅ›wietliÄ‡: g1_pick_and_handover
```
</details>

<details>
<summary><b>ğŸ“· BÅ‚Ä…d: "Kamera nie jest wykrywana"</b></summary>

**Problem:** System nie widzi topikÃ³w z kamery.

**Krok 1:** SprawdÅº czy kamera jest podÅ‚Ä…czona (dla Intel RealSense)
```bash
rs-enumerate-devices
```

**Krok 2:** Uruchom driver kamery
```bash
ros2 run realsense2_camera realsense2_camera_node
```

**Krok 3:** SprawdÅº topiki
```bash
ros2 topic list | grep camera
# Powinno pokazaÄ‡: /camera/color/image_raw, /camera/depth/image_raw
```

**Alternatywa:** UÅ¼yj nagranych danych testowych
```bash
ros2 bag play test_data.bag --loop
```
</details>

<details>
<summary><b>ğŸ¤– BÅ‚Ä…d: "MoveIt 2 nie planuje trajektorii"</b></summary>

**Problem:** `Planning failed` w logach.

**Przyczyna 1:** Cel poza zasiÄ™giem robota
- âœ… **RozwiÄ…zanie:** SprawdÅº odlegÅ‚oÅ›Ä‡ - dla G1 workspace to 0.3-0.8m

**Przyczyna 2:** Kolizja z przeszkodami
- âœ… **RozwiÄ…zanie:** SprawdÅº scenÄ™ planowania w RViz

**Przyczyna 3:** Timeout planowania
```python
# ZwiÄ™ksz timeout w kodzie
self.arm.set_planning_time(15.0)  # domyÅ›lnie: 5.0s
```

**Przyczyna 4:** IK nie ma rozwiÄ…zania
```python
# ZwiÄ™ksz tolerancjÄ™
self.arm.set_goal_position_tolerance(0.01)  # domyÅ›lnie: 0.001
self.arm.set_goal_orientation_tolerance(0.05)
```
</details>

<details>
<summary><b>ğŸ¯ BÅ‚Ä…d: "YOLOv5 nie wykrywa obiektÃ³w"</b></summary>

**Problem:** `/object_detections` jest puste mimo widocznych obiektÃ³w.

**RozwiÄ…zanie 1:** ObniÅ¼ prÃ³g pewnoÅ›ci
```bash
ros2 run g1_pick_and_handover object_detector \
    --ros-args -p confidence_threshold:=0.3  # domyÅ›lnie: 0.6
```

**RozwiÄ…zanie 2:** UÅ¼yj wiÄ™kszego modelu
```bash
ros2 run g1_pick_and_handover object_detector \
    --ros-args -p model_name:=yolov5m  # domyÅ›lnie: yolov5s
```

**RozwiÄ…zanie 3:** SprawdÅº oÅ›wietlenie i czy obiekt jest w zbiorze COCO (80 klas)
</details>

<details>
<summary><b>ğŸ§  Uwaga: "WMA not available, using mock decision making"</b></summary>

**To jest normalne!** 

System automatycznie przeÅ‚Ä…cza siÄ™ na prosty tryb decyzyjny oparty na reguÅ‚ach if-else, ktÃ³ry dziaÅ‚a wystarczajÄ…co dobrze do nauki i testowania.

**Nie potrzebujesz WMA** aby korzystaÄ‡ z systemu. Mock mode jest w peÅ‚ni funkcjonalny.

ğŸ“– WiÄ™cej info: Zobacz [FAQ.md](FAQ.md#q-wma-nie-jest-dostÄ™pny)
</details>

### ğŸ“š WiÄ™cej pomocy

- **FAQ:** [FAQ.md](FAQ.md) - NajczÄ™Å›ciej zadawane pytania
- **Tutoriale:** [TUTORIALS.md](TUTORIALS.md) - Przewodniki krok po kroku
- **Architektura:** [ARCHITECTURE.md](ARCHITECTURE.md) - SzczegÃ³Å‚y techniczne
- **Issues:** [GitHub Issues](https://github.com/MatPomGit/robot-g1-Handover/issues) - ZgÅ‚oÅ› problem

---

## ğŸ“š Dokumentacja Projektu

### ğŸš€ Start szybki
- **[QUICK_START.md](QUICK_START.md)** - âš¡ 5-minutowy przewodnik instalacji i uruchomienia
- **[STATUS.md](STATUS.md)** - ğŸ“Š Dashboard statusu systemu i wydajnoÅ›ci
- **[EXAMPLES.md](EXAMPLES.md)** - ğŸ’» Gotowe przykÅ‚ady kodu do skopiowania
- **[TROUBLESHOOTING.md](TROUBLESHOOTING.md)** - ğŸ” Flowchart rozwiÄ…zywania problemÃ³w
- **[CHECKLIST.md](CHECKLIST.md)** - âœ… Lista kontrolna postÄ™pÃ³w

### ğŸ“– Podstawowa Dokumentacja
- **[FAQ.md](FAQ.md)** - â“ NajczÄ™Å›ciej zadawane pytania i rozwiÄ…zywanie problemÃ³w
- **[TUTORIALS.md](TUTORIALS.md)** - ğŸ“ SzczegÃ³Å‚owe tutoriale krok po kroku dla studentÃ³w
- **[GLOSSARY.md](GLOSSARY.md)** - ğŸ“š SÅ‚ownik terminÃ³w i konceptÃ³w
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - ğŸ“‹ Szybka Å›ciÄ…ga z komendami i parametrami

### ğŸ—ï¸ Dokumentacja Techniczna
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - ğŸ›ï¸ Architektura systemu i przepÅ‚yw danych
- **[TESTING.md](TESTING.md)** - ğŸ§ª Strategia i implementacja testÃ³w
- **[CONTRIBUTING.md](CONTRIBUTING.md)** - ğŸ¤ Przewodnik dla kontrybutorÃ³w

### âš™ï¸ Konfiguracja
- **[config/presets.yaml](config/presets.yaml)** - ğŸšï¸ Gotowe presety: beginner, intermediate, advanced, simulation, debug

#---

## ğŸ’¡ WskazÃ³wki dla efektywnej nauki

### ğŸ“– Rekomendowana Å›cieÅ¼ka nauki

```
DzieÅ„ 1-2:  ğŸ“„ QUICK_START.md â†’ Uruchom system
            â†“
DzieÅ„ 3-5:  ğŸ“ TUTORIALS.md â†’ Zrozum percepcjÄ™ i MoveIt 2
            â†“
DzieÅ„ 6-10: ğŸ—ï¸ ARCHITECTURE.md â†’ ZgÅ‚Ä™b architekturÄ™
            â†“
Dalej:      ğŸ”§ Modyfikuj i eksperymentuj!
```

### ğŸ¯ Checklist poczÄ…tkujÄ…cego

- [ ] System siÄ™ uruchamia (âœ“ QUICK_START.md)
- [ ] Rozumiem topiki ROS 2 (âœ“ TUTORIALS.md - Tutorial 1)
- [ ] Wiem jak dziaÅ‚a YOLO (âœ“ TUTORIALS.md - Tutorial 2)
- [ ] PotrafiÄ™ planowaÄ‡ trajektorie (âœ“ TUTORIALS.md - Tutorial 3)
- [ ] Rozumiem automat stanÃ³w (âœ“ ARCHITECTURE.md)
- [ ] Wiem jak debugowaÄ‡ (âœ“ TROUBLESHOOTING.md)

### ğŸ’¬ SpoÅ‚ecznoÅ›Ä‡ i wsparcie

- **GitHub Issues**: [ZgÅ‚oÅ› problem](https://github.com/MatPomGit/robot-g1-Handover/issues)
- **Discussions**: Zadaj pytanie spoÅ‚ecznoÅ›ci
- **Pull Requests**: WspÃ³Å‚twÃ³rz projekt!

---

## ğŸŒ ZewnÄ™trzne Zasoby

- [ROS 2 Documentation](https://docs.ros.org/en/humble/)
- [MoveIt 2 Tutorials](https://moveit.picknik.ai/humble/index.html)
- [Unitree G1 Robot](https://www.unitree.com/g1)
- [World Model AI](https://worldmodels.github.io/)
- [YOLOv5 Documentation](https://github.com/ultralytics/yolov5)

## ğŸ‘¥ Autorzy i Licencja

Ten projekt jest open-source i dostÄ™pny do celÃ³w edukacyjnych.

## ğŸ¤ WspÃ³Å‚praca

JeÅ›li masz pytania lub sugestie, otwÃ³rz Issue lub Pull Request na GitHubie!

---

## ğŸ“Š Status Projektu

| ModuÅ‚ | Status | Notatki |
|-------|--------|---------|
| ğŸ‘ï¸ **Percepcja (YOLO)** | âœ… DziaÅ‚a | YOLOv5 zaimplementowane |
| ğŸ“ **Estymacja pozy 6D** | âœ… DziaÅ‚a | Pinhole camera model |
| âœ‹ **Detekcja dÅ‚oni** | âš ï¸ Placeholder | Wymaga MediaPipe |
| ğŸ¦¾ **MoveIt 2** | âœ… DziaÅ‚a | Interface gotowy |
| âœ‹ **Gripper control** | âœ… DziaÅ‚a | Open/close zaimplementowane |
| ğŸ§  **WMA (AI)** | âš ï¸ Opcjonalny | Mock mode dziaÅ‚a |
| ğŸ“‹ **FSM** | âœ… DziaÅ‚a | Automat stanÃ³w gotowy |
| ğŸ§ª **Testy** | ğŸš§ W toku | Unit testy do dodania |
| ğŸ“– **Dokumentacja** | âœ… Kompletna | README, FAQ, Tutorials |

**Legenda:**
- âœ… Gotowe i dziaÅ‚a
- âš ï¸ DziaÅ‚a z ograniczeniami
- ğŸš§ W trakcie rozwoju
- âŒ Nie zaimplementowane

---

## ğŸ† OsiÄ…gniÄ™cia i Ulepszenia (Quality of Life)

### Niedawno dodane (2024)

- âœ… **Quick Start Guide** - 5-minutowa instalacja
- âœ… **Troubleshooting Flowchart** - Wizualna diagnostyka problemÃ³w
- âœ… **Configuration Presets** - Gotowe konfiguracje (beginner/advanced)
- âœ… **Enhanced Error Messages** - Komunikaty z sugestiami rozwiÄ…zaÅ„
- âœ… **Emoji Icons** - Kolorowe i intuicyjne logi
- âœ… **Collapsible Sections** - Lepsza organizacja README
- âœ… **Visual Diagrams** - ASCII art diagramy architektury

### Planowane

- [ ] Interactive Setup Wizard (bash script)
- [ ] Status Dashboard (CLI/TUI)
- [ ] Video Tutorials
- [ ] Docker Container
- [ ] Web-based UI Monitor

---

## ğŸ“„ Licencja

Ten projekt jest open-source i dostÄ™pny do celÃ³w edukacyjnych.

---

## â­ Podoba ci siÄ™ projekt?

**Daj gwiazdkÄ™ na GitHubie!** â­ To motywuje nas do dalszego rozwoju.

**Podziel siÄ™ z innymi!** ğŸ“¢ Rozpowszechnij wiedzÄ™ o robotyce HRI.

---

**Uwaga**: Ten projekt jest w fazie rozwoju i sÅ‚uÅ¼y celom edukacyjnym. Przed uÅ¼yciem na prawdziwym robocie naleÅ¼y dokÅ‚adnie przetestowaÄ‡ wszystkie funkcje w symulacji.

---

<div align="center">

### ğŸ¤– Zbudowane z â¤ï¸ dla spoÅ‚ecznoÅ›ci robotyki

**[â¬† PowrÃ³t do gÃ³ry](#-robot-g1---system-przekazywania-obiektÃ³w-handover)**

</div>
